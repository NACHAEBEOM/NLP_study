{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data/'\n",
    "DATA_OUT_PATH = './output/'\n",
    "\n",
    "TRAIN_INPUT_DATA = 'train_input.npy'\n",
    "TRAIN_LABEL_DATA = 'train_label.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.load(open(DATA_IN_PATH + TRAIN_INPUT_DATA, 'rb'))\n",
    "label_data = np.load(open(DATA_IN_PATH + TRAIN_LABEL_DATA, 'rb'))\n",
    "prepro_configs = None\n",
    "\n",
    "with open(DATA_IN_PATH + DATA_CONFIGS, 'r') as f:\n",
    "    prepro_configs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74065"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepro_configs['vocab_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습, 검증용 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SPLIT = 0.1\n",
    "RANDOM_SEED = 13371447\n",
    "\n",
    "train_input, eval_input, train_label, eval_label = train_test_split(input_data, label_data, \n",
    "                                                                    test_size=TEST_SPLIT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 입력 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 3\n",
    "\n",
    "def mapping_fn(X, Y):\n",
    "    inputs, labels = {'x': X}, Y # 데이터 X에대해 'x'라는 이름을 mapping하여 딕셔너리 구조로 사용\n",
    "    return inputs, labels\n",
    "# 모델에 따라 입력값이 하나가 아니라 두개 이상이 될 수도 있다.\n",
    "# 라벨을 제외한 나머지 데이터를 하나의 입력값으로 묶기 위해 mapping 과정을 거친다\n",
    "\n",
    "def train_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((train_input, train_label)) # 주어진 데이터를 묶어서 조각으로 만들고 함께 사용하게 함.\n",
    "    dataset = dataset.shuffle(buffer_size=50000) # 데이터가 섞인다.\n",
    "    dataset = dataset.batch(BATCH_SIZE) # 배치 사이즈를 정한다.\n",
    "    dataset = dataset.repeat(count=NUM_EPOCHS) # Epoch를 설정\n",
    "    dataset = dataset.map(mapping_fn) # 데이터를 맵핑\n",
    "    iterator = dataset.make_one_shot_iterator() # 데이터를 하나씩 사용할 수 있게 해준다.\n",
    "    \n",
    "    return iterator.get_next()\n",
    "\n",
    "def eval_input_fn():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eval_input, eval_label)) \n",
    "    dataset = dataset.map(mapping_fn)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구현 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = prepro_configs['vocab_size']+1\n",
    "WORD_EMBEDDING_DIM = 100\n",
    "HIDDEN_STATE_DIM = 150\n",
    "DENSE_FEATURE_DIM = 150\n",
    "\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74065 74066\n"
     ]
    }
   ],
   "source": [
    "print(len(prepro_configs['vocab']), VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
    "    EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
    "    PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
    "    \n",
    "    embedding_layer = tf.keras.layers.Embedding(\n",
    "                    VOCAB_SIZE,\n",
    "                    WORD_EMBEDDING_DIM)(features['x'])\n",
    "    # 모델에서 데이터를 받게 된다면 시퀀스 형태로 데이터가 입력\n",
    "    # 처음으로 embedding을 진행\n",
    "    \n",
    "    embedding_layer = tf.keras.layers.Dropout(0.2)(embedding_layer)\n",
    "    # Dropout층을 설정\n",
    "    \n",
    "    rnn_layers = [tf.nn.rnn_cell.LSTMCell(size) for size in [HIDDEN_STATE_DIM, HIDDEN_STATE_DIM]]\n",
    "    multi_rnn_cell = tf.nn.rnn_cell.MultiRNNCell(rnn_layers)\n",
    "    # LSTM 모델을 구현하기 위한 코드\n",
    "    # LSTMCell을 생성할 때는 은닉 상태 벡터에 대한 차원만 정의하면 된다.\n",
    "    # 여러 LSTMCell을 쌓게 되면 이를 하나의 MultiRNN으로 묶어야 한다(Wrapping)\n",
    "\n",
    "    outputs, state = tf.nn.dynamic_rnn(cell=multi_rnn_cell,\n",
    "                                       inputs=embedding_layer,\n",
    "                                       dtype=tf.float32)\n",
    "    # 위에서 만든 RNNCell 객체는 시퀀스 한 스텝에 대한 연산만 가능, for문을 통해 여러 연산을 할 수 있게 구현해야한다.\n",
    "    # dynamic_rnnn함수는 for문 없이 순환 신경망을 만들어 주는 역할\n",
    "    \n",
    "    outputs = tf.keras.layers.Dropout(0.2)(outputs)\n",
    "    hidden_layer = tf.keras.layers.Dense(DENSE_FEATURE_DIM, activation=tf.nn.tanh)(outputs[:,-1,:])\n",
    "    # LSTM 신경망의 마지막 출력값을 덴스층에 추가 하기 위하여 output[:, -1, :]을 사용\n",
    "    hidden_layer = tf.keras.layers.Dropout(0.2)(hidden_layer)\n",
    "    logits = tf.keras.layers.Dense(1)(hidden_layer)\n",
    "    # 긍정 / 부정으로 결과를 뽑기 위하여 마지막 층은 1개의 결과값만 나와야 한다(이진분류)\n",
    "    logits = tf.squeeze(logits, axis=-1)\n",
    "    \n",
    "    sigmoid_logits = tf.nn.sigmoid(logits)\n",
    "    \n",
    "    if PREDICT:\n",
    "        predictions = {'sentiment': sigmoid_logits}\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(\n",
    "                  mode=mode,\n",
    "                  predictions=predictions)\n",
    "    \n",
    "    loss = tf.losses.sigmoid_cross_entropy(labels, logits)\n",
    "    \n",
    "    if EVAL:\n",
    "        accuracy = tf.metrics.accuracy(labels, tf.round(sigmoid_logits))\n",
    "        eval_metric_ops = {'acc': accuracy}\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "    \n",
    "    if TRAIN:\n",
    "        global_step = tf.train.get_global_step()\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step)\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "                  mode=mode,\n",
    "                  train_op=train_op,\n",
    "                  loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './output/checkpoint/rnn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000020FCEB7DC88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(DATA_OUT_PATH):\n",
    "    os.makedirs(DATA_OUT_PATH)\n",
    "\n",
    "est = tf.estimator.Estimator(model_fn=model_fn,\n",
    "                             model_dir=DATA_OUT_PATH + 'checkpoint/rnn') \n",
    "# 모델을 작성한 함수를 통해 에스티메이터 객체 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./output/checkpoint/rnn\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.6906093, step = 1\n",
      "INFO:tensorflow:global_step/sec: 3.05105\n",
      "INFO:tensorflow:loss = 0.6660559, step = 101 (32.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.127\n",
      "INFO:tensorflow:loss = 0.6946002, step = 201 (31.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.12066\n",
      "INFO:tensorflow:loss = 0.69460976, step = 301 (32.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.15233\n",
      "INFO:tensorflow:loss = 0.6882217, step = 401 (31.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10551\n",
      "INFO:tensorflow:loss = 0.6806458, step = 501 (32.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.13182\n",
      "INFO:tensorflow:loss = 0.6909116, step = 601 (31.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.20435\n",
      "INFO:tensorflow:loss = 0.6995862, step = 701 (31.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.19763\n",
      "INFO:tensorflow:loss = 0.59115994, step = 801 (31.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.10108\n",
      "INFO:tensorflow:loss = 0.55779046, step = 901 (32.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.15793\n",
      "INFO:tensorflow:loss = 0.7274654, step = 1001 (31.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.20763\n",
      "INFO:tensorflow:loss = 0.6638336, step = 1101 (31.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.98885\n",
      "INFO:tensorflow:loss = 0.62231493, step = 1201 (33.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.12409\n",
      "INFO:tensorflow:loss = 0.66197073, step = 1301 (32.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.19558\n",
      "INFO:tensorflow:loss = 0.6576163, step = 1401 (31.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.14165\n",
      "INFO:tensorflow:loss = 0.41957024, step = 1501 (31.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07992\n",
      "INFO:tensorflow:loss = 0.6832772, step = 1601 (32.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09139\n",
      "INFO:tensorflow:loss = 0.5812172, step = 1701 (32.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.14784\n",
      "INFO:tensorflow:loss = 0.60459995, step = 1801 (31.768 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1873 into ./output/checkpoint/rnn\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 2.95657\n",
      "INFO:tensorflow:loss = 0.5017786, step = 1901 (33.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.07697\n",
      "INFO:tensorflow:loss = 0.5670966, step = 2001 (32.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.02056\n",
      "INFO:tensorflow:loss = 0.64281905, step = 2101 (33.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11545\n",
      "INFO:tensorflow:loss = 0.52614456, step = 2201 (32.094 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11159\n",
      "INFO:tensorflow:loss = 0.6367975, step = 2301 (32.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.96992\n",
      "INFO:tensorflow:loss = 0.4568945, step = 2401 (33.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06471\n",
      "INFO:tensorflow:loss = 0.66376555, step = 2501 (32.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.11214\n",
      "INFO:tensorflow:loss = 0.70830214, step = 2601 (32.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.06938\n",
      "INFO:tensorflow:loss = 0.6865498, step = 2701 (32.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08119\n",
      "INFO:tensorflow:loss = 0.65970623, step = 2801 (32.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.15455\n",
      "INFO:tensorflow:loss = 0.6981084, step = 2901 (31.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09388\n",
      "INFO:tensorflow:loss = 0.6621066, step = 3001 (32.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.18995\n",
      "INFO:tensorflow:loss = 0.64132345, step = 3101 (31.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.22399\n",
      "INFO:tensorflow:loss = 0.4465351, step = 3201 (31.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.18697\n",
      "INFO:tensorflow:loss = 0.48509687, step = 3301 (31.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.12341\n",
      "INFO:tensorflow:loss = 0.43094623, step = 3401 (32.016 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.16976\n",
      "INFO:tensorflow:loss = 0.33741972, step = 3501 (31.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.1199\n",
      "INFO:tensorflow:loss = 0.30008802, step = 3601 (32.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.17389\n",
      "INFO:tensorflow:loss = 0.33171472, step = 3701 (31.507 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3737 into ./output/checkpoint/rnn\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.0332\n",
      "INFO:tensorflow:loss = 0.31098384, step = 3801 (32.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.1663\n",
      "INFO:tensorflow:loss = 0.25232884, step = 3901 (31.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.08573\n",
      "INFO:tensorflow:loss = 0.35790688, step = 4001 (32.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.20092\n",
      "INFO:tensorflow:loss = 0.20686808, step = 4101 (31.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.14182\n",
      "INFO:tensorflow:loss = 0.3509192, step = 4201 (31.829 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4221 into ./output/checkpoint/rnn\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.49057198.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x20fceb7dc18>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "est.train(train_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검증 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-29-11:26:27\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./output/checkpoint/rnn\\model.ckpt-4221\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-29-11:26:39\n",
      "INFO:tensorflow:Saving dict for global step 4221: acc = 0.8468, global_step = 4221, loss = 0.34527427\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4221: ./output/checkpoint/rnn\\model.ckpt-4221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.8468, 'loss': 0.34527427, 'global_step': 4221}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.evaluate(eval_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_OUT_PATH = './output/'\n",
    "TEST_INPUT_DATA = 'test_input.npy'\n",
    "TEST_ID_DATA = 'test_id.npy'\n",
    "\n",
    "test_input_data = np.load(open(DATA_IN_PATH + TEST_INPUT_DATA, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\":test_input_data}, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python\\python36\\venv\\kmu\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From c:\\python\\python36\\venv\\kmu\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./output/checkpoint/rnn\\model.ckpt-4221\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From c:\\python\\python36\\venv\\kmu\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    }
   ],
   "source": [
    "predictions = np.array([p['sentiment'] for p in est.predict(input_fn=\n",
    "predict_input_fn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = np.load(open(DATA_IN_PATH + TEST_ID_DATA, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_OUT_PATH):\n",
    "    os.makedirs(DATA_OUT_PATH)\n",
    "\n",
    "output = pd.DataFrame(data={\"id\": list(test_id), \"sentiment\":list(predictions)} )\n",
    "output.to_csv(DATA_OUT_PATH + 'movie_review_result_rnn.csv', index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 캐글에서 0.92585점으로 220등 정도의 성적(public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
